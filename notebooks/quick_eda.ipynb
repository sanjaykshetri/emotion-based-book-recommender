{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931e5cf6",
   "metadata": {},
   "source": [
    "# Quick EDA - GoodBooks-10k Dataset\n",
    "\n",
    "Exploratory Data Analysis for the Emotion-Based Book Recommender project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53da5059",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c39632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c415ec",
   "metadata": {},
   "source": [
    "## 2. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d226bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\"../data/raw/books.csv\")\n",
    "ratings = pd.read_csv(\"../data/raw/ratings.csv\")\n",
    "book_tags = pd.read_csv(\"../data/raw/book_tags.csv\")\n",
    "tags = pd.read_csv(\"../data/raw/tags.csv\")\n",
    "to_read = pd.read_csv(\"../data/raw/to_read.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23957b",
   "metadata": {},
   "source": [
    "## 3. Display Dataset Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9826efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books shape: (10000, 23)\n",
      "Ratings shape: (981756, 3)\n",
      "Book Tags shape: (999912, 3)\n",
      "Tags shape: (34252, 2)\n",
      "To Read shape: (912705, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Books shape: {books.shape}\")\n",
    "print(f\"Ratings shape: {ratings.shape}\")\n",
    "print(f\"Book Tags shape: {book_tags.shape}\")\n",
    "print(f\"Tags shape: {tags.shape}\")\n",
    "print(f\"To Read shape: {to_read.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7400422c",
   "metadata": {},
   "source": [
    "## 4. Preview Data - Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d74f560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>title</th>\n",
       "      <th>language_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPr√©</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>Twilight (Twilight, #1)</td>\n",
       "      <td>en-US</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>2657</td>\n",
       "      <td>3275794</td>\n",
       "      <td>487</td>\n",
       "      <td>61120081</td>\n",
       "      <td>9.780061e+12</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3198671</td>\n",
       "      <td>3340896</td>\n",
       "      <td>72586</td>\n",
       "      <td>60427</td>\n",
       "      <td>117415</td>\n",
       "      <td>446835</td>\n",
       "      <td>1001952</td>\n",
       "      <td>1714267</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>4671</td>\n",
       "      <td>245494</td>\n",
       "      <td>1356</td>\n",
       "      <td>743273567</td>\n",
       "      <td>9.780743e+12</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>eng</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2683664</td>\n",
       "      <td>2773745</td>\n",
       "      <td>51992</td>\n",
       "      <td>86236</td>\n",
       "      <td>197621</td>\n",
       "      <td>606158</td>\n",
       "      <td>936012</td>\n",
       "      <td>947718</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  book_id  best_book_id  work_id  books_count       isbn        isbn13  \\\n",
       "0   1  2767052       2767052  2792775          272  439023483  9.780439e+12   \n",
       "1   2        3             3  4640799          491  439554934  9.780440e+12   \n",
       "2   3    41865         41865  3212258          226  316015849  9.780316e+12   \n",
       "3   4     2657          2657  3275794          487   61120081  9.780061e+12   \n",
       "4   5     4671          4671   245494         1356  743273567  9.780743e+12   \n",
       "\n",
       "                       authors  original_publication_year  \\\n",
       "0              Suzanne Collins                     2008.0   \n",
       "1  J.K. Rowling, Mary GrandPr√©                     1997.0   \n",
       "2              Stephenie Meyer                     2005.0   \n",
       "3                   Harper Lee                     1960.0   \n",
       "4          F. Scott Fitzgerald                     1925.0   \n",
       "\n",
       "                             original_title  \\\n",
       "0                          The Hunger Games   \n",
       "1  Harry Potter and the Philosopher's Stone   \n",
       "2                                  Twilight   \n",
       "3                     To Kill a Mockingbird   \n",
       "4                          The Great Gatsby   \n",
       "\n",
       "                                               title language_code  \\\n",
       "0            The Hunger Games (The Hunger Games, #1)           eng   \n",
       "1  Harry Potter and the Sorcerer's Stone (Harry P...           eng   \n",
       "2                            Twilight (Twilight, #1)         en-US   \n",
       "3                              To Kill a Mockingbird           eng   \n",
       "4                                   The Great Gatsby           eng   \n",
       "\n",
       "   average_rating  ratings_count  work_ratings_count  work_text_reviews_count  \\\n",
       "0            4.34        4780653             4942365                   155254   \n",
       "1            4.44        4602479             4800065                    75867   \n",
       "2            3.57        3866839             3916824                    95009   \n",
       "3            4.25        3198671             3340896                    72586   \n",
       "4            3.89        2683664             2773745                    51992   \n",
       "\n",
       "   ratings_1  ratings_2  ratings_3  ratings_4  ratings_5  \\\n",
       "0      66715     127936     560092    1481305    2706317   \n",
       "1      75504     101676     455024    1156318    3011543   \n",
       "2     456191     436802     793319     875073    1355439   \n",
       "3      60427     117415     446835    1001952    1714267   \n",
       "4      86236     197621     606158     936012     947718   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "3  https://images.gr-assets.com/books/1361975680m...   \n",
       "4  https://images.gr-assets.com/books/1490528560m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  \n",
       "3  https://images.gr-assets.com/books/1361975680s...  \n",
       "4  https://images.gr-assets.com/books/1490528560s...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9492e88",
   "metadata": {},
   "source": [
    "## 5. Understand Dataset Structure & Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a19fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BOOKS DATASET\n",
      "============================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   id                         10000 non-null  int64  \n",
      " 1   book_id                    10000 non-null  int64  \n",
      " 2   best_book_id               10000 non-null  int64  \n",
      " 3   work_id                    10000 non-null  int64  \n",
      " 4   books_count                10000 non-null  int64  \n",
      " 5   isbn                       9300 non-null   object \n",
      " 6   isbn13                     9415 non-null   float64\n",
      " 7   authors                    10000 non-null  object \n",
      " 8   original_publication_year  9979 non-null   float64\n",
      " 9   original_title             9415 non-null   object \n",
      " 10  title                      10000 non-null  object \n",
      " 11  language_code              8916 non-null   object \n",
      " 12  average_rating             10000 non-null  float64\n",
      " 13  ratings_count              10000 non-null  int64  \n",
      " 14  work_ratings_count         10000 non-null  int64  \n",
      " 15  work_text_reviews_count    10000 non-null  int64  \n",
      " 16  ratings_1                  10000 non-null  int64  \n",
      " 17  ratings_2                  10000 non-null  int64  \n",
      " 18  ratings_3                  10000 non-null  int64  \n",
      " 19  ratings_4                  10000 non-null  int64  \n",
      " 20  ratings_5                  10000 non-null  int64  \n",
      " 21  image_url                  10000 non-null  object \n",
      " 22  small_image_url            10000 non-null  object \n",
      "dtypes: float64(3), int64(13), object(7)\n",
      "memory usage: 1.8+ MB\n",
      "\n",
      "Column names: ['id', 'book_id', 'best_book_id', 'work_id', 'books_count', 'isbn', 'isbn13', 'authors', 'original_publication_year', 'original_title', 'title', 'language_code', 'average_rating', 'ratings_count', 'work_ratings_count', 'work_text_reviews_count', 'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5', 'image_url', 'small_image_url']\n"
     ]
    }
   ],
   "source": [
    "# Books dataset - Core book metadata\n",
    "print(\"=\" * 60)\n",
    "print(\"BOOKS DATASET\")\n",
    "print(\"=\" * 60)\n",
    "books.info()\n",
    "print(\"\\nColumn names:\", books.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "745178db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RATINGS DATASET\n",
      "============================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 981756 entries, 0 to 981755\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count   Dtype\n",
      "---  ------   --------------   -----\n",
      " 0   book_id  981756 non-null  int64\n",
      " 1   user_id  981756 non-null  int64\n",
      " 2   rating   981756 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 22.5 MB\n",
      "\n",
      "Sample ratings:\n",
      "   book_id  user_id  rating\n",
      "0        1      314       5\n",
      "1        1      439       3\n",
      "2        1      588       5\n",
      "3        1     1169       4\n",
      "4        1     1185       4\n"
     ]
    }
   ],
   "source": [
    "# Ratings dataset - User-book interactions\n",
    "print(\"=\" * 60)\n",
    "print(\"RATINGS DATASET\")\n",
    "print(\"=\" * 60)\n",
    "ratings.info()\n",
    "print(\"\\nSample ratings:\")\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ed6148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TAGS DATASET - KEY FOR EMOTIONAL CONTEXT\n",
      "============================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34252 entries, 0 to 34251\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   tag_id    34252 non-null  int64 \n",
      " 1   tag_name  34252 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 535.3+ KB\n",
      "\n",
      "Sample tags:\n",
      "    tag_id                     tag_name\n",
      "0        0                            -\n",
      "1        1                         --1-\n",
      "2        2                        --10-\n",
      "3        3                        --12-\n",
      "4        4                       --122-\n",
      "5        5                       --166-\n",
      "6        6                        --17-\n",
      "7        7                        --19-\n",
      "8        8                         --2-\n",
      "9        9                       --258-\n",
      "10      10                         --3-\n",
      "11      11                        --33-\n",
      "12      12                         --4-\n",
      "13      13                         --5-\n",
      "14      14                        --51-\n",
      "15      15                         --6-\n",
      "16      16                        --62-\n",
      "17      17                         --8-\n",
      "18      18                        --99-\n",
      "19      19  --available-at-raspberrys--\n",
      "\n",
      "Total unique tags: 34252\n"
     ]
    }
   ],
   "source": [
    "# Tags dataset - Emotional/thematic descriptors!\n",
    "print(\"=\" * 60)\n",
    "print(\"TAGS DATASET - KEY FOR EMOTIONAL CONTEXT\")\n",
    "print(\"=\" * 60)\n",
    "tags.info()\n",
    "print(\"\\nSample tags:\")\n",
    "print(tags.head(20))\n",
    "print(f\"\\nTotal unique tags: {len(tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b646e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BOOK_TAGS DATASET - Book-Tag Mappings\n",
      "============================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999912 entries, 0 to 999911\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count   Dtype\n",
      "---  ------             --------------   -----\n",
      " 0   goodreads_book_id  999912 non-null  int64\n",
      " 1   tag_id             999912 non-null  int64\n",
      " 2   count              999912 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 22.9 MB\n",
      "\n",
      "Sample book-tag mappings:\n",
      "   goodreads_book_id  tag_id   count\n",
      "0                  1   30574  167697\n",
      "1                  1   11305   37174\n",
      "2                  1   11557   34173\n",
      "3                  1    8717   12986\n",
      "4                  1   33114   12716\n"
     ]
    }
   ],
   "source": [
    "# Book Tags - Links books to tags\n",
    "print(\"=\" * 60)\n",
    "print(\"BOOK_TAGS DATASET - Book-Tag Mappings\")\n",
    "print(\"=\" * 60)\n",
    "book_tags.info()\n",
    "print(\"\\nSample book-tag mappings:\")\n",
    "print(book_tags.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb01b1",
   "metadata": {},
   "source": [
    "## 6. Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91d9e84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Books Dataset:\n",
      "id                              0\n",
      "book_id                         0\n",
      "best_book_id                    0\n",
      "work_id                         0\n",
      "books_count                     0\n",
      "isbn                          700\n",
      "isbn13                        585\n",
      "authors                         0\n",
      "original_publication_year      21\n",
      "original_title                585\n",
      "title                           0\n",
      "language_code                1084\n",
      "average_rating                  0\n",
      "ratings_count                   0\n",
      "work_ratings_count              0\n",
      "work_text_reviews_count         0\n",
      "ratings_1                       0\n",
      "ratings_2                       0\n",
      "ratings_3                       0\n",
      "ratings_4                       0\n",
      "ratings_5                       0\n",
      "image_url                       0\n",
      "small_image_url                 0\n",
      "dtype: int64\n",
      "\n",
      "Percentage missing:\n",
      "id                            0.00\n",
      "book_id                       0.00\n",
      "best_book_id                  0.00\n",
      "work_id                       0.00\n",
      "books_count                   0.00\n",
      "isbn                          7.00\n",
      "isbn13                        5.85\n",
      "authors                       0.00\n",
      "original_publication_year     0.21\n",
      "original_title                5.85\n",
      "title                         0.00\n",
      "language_code                10.84\n",
      "average_rating                0.00\n",
      "ratings_count                 0.00\n",
      "work_ratings_count            0.00\n",
      "work_text_reviews_count       0.00\n",
      "ratings_1                     0.00\n",
      "ratings_2                     0.00\n",
      "ratings_3                     0.00\n",
      "ratings_4                     0.00\n",
      "ratings_5                     0.00\n",
      "image_url                     0.00\n",
      "small_image_url               0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing Values in Books Dataset:\")\n",
    "print(books.isnull().sum())\n",
    "print(f\"\\nPercentage missing:\")\n",
    "print((books.isnull().sum() / len(books) * 100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a7e81",
   "metadata": {},
   "source": [
    "## 7. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eff9b796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books Dataset Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9.415000e+03</td>\n",
       "      <td>9979.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>5.264697e+06</td>\n",
       "      <td>5.471214e+06</td>\n",
       "      <td>8.646183e+06</td>\n",
       "      <td>75.712700</td>\n",
       "      <td>9.755044e+12</td>\n",
       "      <td>1981.987674</td>\n",
       "      <td>4.002191</td>\n",
       "      <td>5.400124e+04</td>\n",
       "      <td>5.968732e+04</td>\n",
       "      <td>2919.955300</td>\n",
       "      <td>1345.040600</td>\n",
       "      <td>3110.885000</td>\n",
       "      <td>11475.893800</td>\n",
       "      <td>1.996570e+04</td>\n",
       "      <td>2.378981e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.575462e+06</td>\n",
       "      <td>7.827330e+06</td>\n",
       "      <td>1.175106e+07</td>\n",
       "      <td>170.470728</td>\n",
       "      <td>4.428619e+11</td>\n",
       "      <td>152.576665</td>\n",
       "      <td>0.254427</td>\n",
       "      <td>1.573700e+05</td>\n",
       "      <td>1.678038e+05</td>\n",
       "      <td>6124.378132</td>\n",
       "      <td>6635.626263</td>\n",
       "      <td>9717.123578</td>\n",
       "      <td>28546.449183</td>\n",
       "      <td>5.144736e+04</td>\n",
       "      <td>7.976889e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.700000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.951703e+08</td>\n",
       "      <td>-1750.000000</td>\n",
       "      <td>2.470000</td>\n",
       "      <td>2.716000e+03</td>\n",
       "      <td>5.510000e+03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>7.500000e+02</td>\n",
       "      <td>7.540000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>4.627575e+04</td>\n",
       "      <td>4.791175e+04</td>\n",
       "      <td>1.008841e+06</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>1.356875e+04</td>\n",
       "      <td>1.543875e+04</td>\n",
       "      <td>694.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>656.000000</td>\n",
       "      <td>3112.000000</td>\n",
       "      <td>5.405750e+03</td>\n",
       "      <td>5.334000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>3.949655e+05</td>\n",
       "      <td>4.251235e+05</td>\n",
       "      <td>2.719524e+06</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>9.780452e+12</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>2.115550e+04</td>\n",
       "      <td>2.383250e+04</td>\n",
       "      <td>1402.000000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>1163.000000</td>\n",
       "      <td>4894.000000</td>\n",
       "      <td>8.269500e+03</td>\n",
       "      <td>8.836000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>9.382225e+06</td>\n",
       "      <td>9.636112e+06</td>\n",
       "      <td>1.451775e+07</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>9.780831e+12</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>4.180000</td>\n",
       "      <td>4.105350e+04</td>\n",
       "      <td>4.591500e+04</td>\n",
       "      <td>2744.250000</td>\n",
       "      <td>885.000000</td>\n",
       "      <td>2353.250000</td>\n",
       "      <td>9287.000000</td>\n",
       "      <td>1.602350e+04</td>\n",
       "      <td>1.730450e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>3.328864e+07</td>\n",
       "      <td>3.553423e+07</td>\n",
       "      <td>5.639960e+07</td>\n",
       "      <td>3455.000000</td>\n",
       "      <td>9.790008e+12</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>4.820000</td>\n",
       "      <td>4.780653e+06</td>\n",
       "      <td>4.942365e+06</td>\n",
       "      <td>155254.000000</td>\n",
       "      <td>456191.000000</td>\n",
       "      <td>436802.000000</td>\n",
       "      <td>793319.000000</td>\n",
       "      <td>1.481305e+06</td>\n",
       "      <td>3.011543e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       book_id  best_book_id       work_id   books_count  \\\n",
       "count  10000.00000  1.000000e+04  1.000000e+04  1.000000e+04  10000.000000   \n",
       "mean    5000.50000  5.264697e+06  5.471214e+06  8.646183e+06     75.712700   \n",
       "std     2886.89568  7.575462e+06  7.827330e+06  1.175106e+07    170.470728   \n",
       "min        1.00000  1.000000e+00  1.000000e+00  8.700000e+01      1.000000   \n",
       "25%     2500.75000  4.627575e+04  4.791175e+04  1.008841e+06     23.000000   \n",
       "50%     5000.50000  3.949655e+05  4.251235e+05  2.719524e+06     40.000000   \n",
       "75%     7500.25000  9.382225e+06  9.636112e+06  1.451775e+07     67.000000   \n",
       "max    10000.00000  3.328864e+07  3.553423e+07  5.639960e+07   3455.000000   \n",
       "\n",
       "             isbn13  original_publication_year  average_rating  ratings_count  \\\n",
       "count  9.415000e+03                9979.000000    10000.000000   1.000000e+04   \n",
       "mean   9.755044e+12                1981.987674        4.002191   5.400124e+04   \n",
       "std    4.428619e+11                 152.576665        0.254427   1.573700e+05   \n",
       "min    1.951703e+08               -1750.000000        2.470000   2.716000e+03   \n",
       "25%    9.780316e+12                1990.000000        3.850000   1.356875e+04   \n",
       "50%    9.780452e+12                2004.000000        4.020000   2.115550e+04   \n",
       "75%    9.780831e+12                2011.000000        4.180000   4.105350e+04   \n",
       "max    9.790008e+12                2017.000000        4.820000   4.780653e+06   \n",
       "\n",
       "       work_ratings_count  work_text_reviews_count      ratings_1  \\\n",
       "count        1.000000e+04             10000.000000   10000.000000   \n",
       "mean         5.968732e+04              2919.955300    1345.040600   \n",
       "std          1.678038e+05              6124.378132    6635.626263   \n",
       "min          5.510000e+03                 3.000000      11.000000   \n",
       "25%          1.543875e+04               694.000000     196.000000   \n",
       "50%          2.383250e+04              1402.000000     391.000000   \n",
       "75%          4.591500e+04              2744.250000     885.000000   \n",
       "max          4.942365e+06            155254.000000  456191.000000   \n",
       "\n",
       "           ratings_2      ratings_3     ratings_4     ratings_5  \n",
       "count   10000.000000   10000.000000  1.000000e+04  1.000000e+04  \n",
       "mean     3110.885000   11475.893800  1.996570e+04  2.378981e+04  \n",
       "std      9717.123578   28546.449183  5.144736e+04  7.976889e+04  \n",
       "min        30.000000     323.000000  7.500000e+02  7.540000e+02  \n",
       "25%       656.000000    3112.000000  5.405750e+03  5.334000e+03  \n",
       "50%      1163.000000    4894.000000  8.269500e+03  8.836000e+03  \n",
       "75%      2353.250000    9287.000000  1.602350e+04  1.730450e+04  \n",
       "max    436802.000000  793319.000000  1.481305e+06  3.011543e+06  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Books statistics\n",
    "print(\"Books Dataset Statistics:\")\n",
    "books.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f0733ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Distribution:\n",
      "rating\n",
      "1     19575\n",
      "2     63231\n",
      "3    248623\n",
      "4    357366\n",
      "5    292961\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average rating: 3.86\n",
      "Median rating: 4.0\n"
     ]
    }
   ],
   "source": [
    "# Ratings distribution\n",
    "print(\"Ratings Distribution:\")\n",
    "print(ratings['rating'].value_counts().sort_index())\n",
    "print(f\"\\nAverage rating: {ratings['rating'].mean():.2f}\")\n",
    "print(f\"Median rating: {ratings['rating'].median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb5c4e9",
   "metadata": {},
   "source": [
    "## 8. Explore Tags for Emotional Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e419005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 415 emotion-related tags:\n",
      "['0-love-funny', '1930-s-depression-era', '1930-s-great-depression', '4-stars-loved-it', '48-days-to-the-work-you-love', 'a-beautiful-dark', 'a-fun-and-enjoyable-series', 'a-love-story', 'a-search-for-peace', 'a-tale-dark-and-grimm', 'absolutely-loved', 'adoption-families-foster-homes-love', 'after-dark', 'afterdark', 'all-love', 'already-read-and-enjoyed', 'ambassador', 'ambassador-daughter-kidnapping', 'ancient-darkness', 'angels-of-the-dark', 'angels-of-the-dark-series', 'anger', 'anger-management', 'animal-lover', 'animal-lovers', 'anthony-hope', 'apple-love', 'are-you-afraid-of-the-dark', 'assad-khalil', 'austen-inspired', 'baby-love', 'be-the-writer-you-love', 'beloved', 'beloved-books', 'beloved-by-me', 'black-love', 'book-lovers-calendar', 'books-i-enjoyed-reading', 'books-i-love', 'books-i-loved', 'books-i-loved-as-a-child', 'books-i-loved-as-a-kid', 'books-i-would-love-to-burn', 'books-that-i-love', 'books-to-love', 'brotherly-love', 'bushrangers', 'business-motivation', 'c-readers-enjoyed', 'can-love-happen-twice']\n"
     ]
    }
   ],
   "source": [
    "# Search for emotion-related tags\n",
    "emotion_keywords = ['sad', 'happy', 'hope', 'anxious', 'lonely', 'comfort', 'inspire', \n",
    "                    'depress', 'uplifting', 'dark', 'joy', 'fear', 'calm', 'stress',\n",
    "                    'heartbreak', 'love', 'anger', 'grief', 'peace', 'motivat']\n",
    "\n",
    "emotion_tags = tags[tags['tag_name'].str.lower().str.contains('|'.join(emotion_keywords), na=False)]\n",
    "print(f\"Found {len(emotion_tags)} emotion-related tags:\")\n",
    "print(emotion_tags['tag_name'].tolist()[:50])  # Show first 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af064c79",
   "metadata": {},
   "source": [
    "## 9. Dataset Relationships & Project Context\n",
    "\n",
    "### How datasets connect:\n",
    "1. **books.csv** ‚Üí Core metadata (title, author, ratings, publication year)\n",
    "2. **tags.csv** ‚Üí User-generated descriptors (genres, themes, moods, emotions)\n",
    "3. **book_tags.csv** ‚Üí Links books to tags (many-to-many relationship)\n",
    "4. **ratings.csv** ‚Üí User preferences (can identify books that resonate emotionally)\n",
    "5. **to_read.csv** ‚Üí User intentions (signals interest/desire)\n",
    "\n",
    "### Relevance to Emotion-Based Recommendations:\n",
    "- **Tags** may contain emotion words (comforting, heartbreaking, uplifting)\n",
    "- **Ratings + Tags** can show which emotional themes get high ratings\n",
    "- **Book metadata** (title, author, average_rating) provides content features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c0f66",
   "metadata": {},
   "source": [
    "## 10. Key Research Questions\n",
    "\n",
    "### üîç Data Understanding Questions:\n",
    "1. What percentage of books have emotion-related tags?\n",
    "2. Which tags appear most frequently across all books?\n",
    "3. Are there clusters of books with similar emotional tags?\n",
    "4. Do highly-rated books correlate with specific emotional themes?\n",
    "\n",
    "### üéØ Modeling Questions:\n",
    "5. Can we extract emotional signals from book titles or existing tags?\n",
    "6. Should we map emotions to tag clusters (e.g., \"comfort reading\" = cozy + uplifting)?\n",
    "7. What features best predict emotional fit? (tags, ratings, genres, etc.)\n",
    "8. How do we handle books with NO emotional tags?\n",
    "\n",
    "### üöÄ Recommendation Questions:\n",
    "9. Given emotion \"anxious\" ‚Üí which book features correlate with anxiety relief?\n",
    "10. Can we create an emotion lexicon mapping emotions to book characteristics?\n",
    "11. Should we use collaborative filtering (users with similar emotions liked X) or content-based?\n",
    "12. How do we validate that recommendations actually match the emotional need?\n",
    "\n",
    "### üìä Evaluation Questions:\n",
    "13. What metrics best capture \"emotional fit\"? (Beyond Precision@K)\n",
    "14. Can we get human labels for a small test set? (emotion ‚Üí book pairs)\n",
    "15. Should we use sentiment analysis on reviews as ground truth?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e894031",
   "metadata": {},
   "source": [
    "## 11. Strategic Dataset Merging\n",
    "\n",
    "### ‚ö†Ô∏è Don't merge everything into one giant table!\n",
    "\n",
    "**Instead, create purpose-specific merged datasets:**\n",
    "\n",
    "1. **Books + Tags** ‚Üí For content-based emotion matching\n",
    "2. **Books + Ratings** ‚Üí For popularity/quality filtering  \n",
    "3. **Keep user interactions separate** ‚Üí Only merge if doing collaborative filtering\n",
    "\n",
    "### Why selective merging?\n",
    "- Avoids memory issues with massive joins\n",
    "- Keeps datasets interpretable\n",
    "- Makes debugging easier\n",
    "- Allows flexible modeling approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dc9e98",
   "metadata": {},
   "source": [
    "### 11.1 Create Book-Tag Feature Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce758b",
   "metadata": {},
   "source": [
    "#### Step 1: Add Tag Names to Book-Tag Mappings\n",
    "\n",
    "**What's happening:** The `book_tags` table only has tag IDs. We merge it with the `tags` table to get actual tag names.\n",
    "\n",
    "**Technical details:**\n",
    "- Left join on `tag_id` preserves all book-tag relationships\n",
    "- Results in a table with: `goodreads_book_id`, `tag_id`, `tag_name`, `count` (popularity of that tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bca638",
   "metadata": {},
   "source": [
    "**Goal:** Create a unified dataset where each book has all its associated tags in a readable format.\n",
    "\n",
    "**Why?** The raw data has books and tags in separate tables with a junction table (book_tags) linking them. We need to combine these to:\n",
    "- See what emotional/thematic descriptors each book has\n",
    "- Enable text-based similarity matching (e.g., TF-IDF on tags)\n",
    "- Identify books suitable for emotion-based recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab9f3921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book-tags with names: (999912, 4)\n",
      "   goodreads_book_id  tag_id   count           tag_name\n",
      "0                  1   30574  167697            to-read\n",
      "1                  1   11305   37174            fantasy\n",
      "2                  1   11557   34173          favorites\n",
      "3                  1    8717   12986  currently-reading\n",
      "4                  1   33114   12716        young-adult\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Merge book_tags with tags to get tag names\n",
    "book_tags_named = book_tags.merge(\n",
    "    tags, \n",
    "    left_on='tag_id', \n",
    "    right_on='tag_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Book-tags with names: {book_tags_named.shape}\")\n",
    "print(book_tags_named.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6f2a4",
   "metadata": {},
   "source": [
    "#### Step 2: Aggregate Tags Per Book\n",
    "\n",
    "**What's happening:** Each book has MULTIPLE tags. We collapse all tags for each book into a single row.\n",
    "\n",
    "**Why?** For ML models, we typically want one row per book with all features. This creates:\n",
    "- `all_tags`: Comma-separated string of all tag names (useful for text analysis)\n",
    "- `total_tag_count`: Sum of tag counts (indicates overall tagging activity)\n",
    "\n",
    "**Use case:** Later, we can use `all_tags` as input for TF-IDF vectorization or embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1848b495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books with aggregated tags: (10000, 3)\n",
      "   goodreads_book_id                                           all_tags  \\\n",
      "0                  1  to-read, fantasy, favorites, currently-reading...   \n",
      "1                  2  to-read, currently-reading, fantasy, favorites...   \n",
      "2                  3  to-read, favorites, fantasy, currently-reading...   \n",
      "3                  5  favorites, fantasy, currently-reading, young-a...   \n",
      "4                  6  fantasy, young-adult, fiction, harry-potter, o...   \n",
      "\n",
      "   total_tag_count  \n",
      "0           359447  \n",
      "1            73667  \n",
      "2           786374  \n",
      "3           227215  \n",
      "4           141246  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Aggregate tags per book (create a tag list for each book)\n",
    "books_with_tags = book_tags_named.groupby('goodreads_book_id').agg({\n",
    "    'tag_name': lambda x: ', '.join(x.dropna().astype(str)),  # Combine all tags\n",
    "    'count': 'sum'  # Total tag count\n",
    "}).reset_index()\n",
    "\n",
    "books_with_tags.columns = ['goodreads_book_id', 'all_tags', 'total_tag_count']\n",
    "\n",
    "print(f\"Books with aggregated tags: {books_with_tags.shape}\")\n",
    "print(books_with_tags.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076603ba",
   "metadata": {},
   "source": [
    "#### Step 3: Merge with Books Metadata\n",
    "\n",
    "**What's happening:** Combine the aggregated tags with the main books dataset.\n",
    "\n",
    "**Left join strategy:** We keep ALL books (even those without tags) because:\n",
    "- Books without tags still have other features (title, author, ratings)\n",
    "- We'll need to handle missing tags in our model (imputation, cold-start problem)\n",
    "\n",
    "**Result:** Enriched dataset with book metadata + tag features in one place.\n",
    "\n",
    "**Check:** After merge, inspect how many books are missing tags (data quality issue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c27c33ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Enriched books dataset: (10000, 26)\n",
      "Books with tags: 10000\n",
      "Books without tags: 0\n",
      "\n",
      "Sample:\n",
      "                                               title  \\\n",
      "0            The Hunger Games (The Hunger Games, #1)   \n",
      "1  Harry Potter and the Sorcerer's Stone (Harry P...   \n",
      "2                            Twilight (Twilight, #1)   \n",
      "3                              To Kill a Mockingbird   \n",
      "4                                   The Great Gatsby   \n",
      "\n",
      "                       authors  average_rating  \\\n",
      "0              Suzanne Collins            4.34   \n",
      "1  J.K. Rowling, Mary GrandPr√©            4.44   \n",
      "2              Stephenie Meyer            3.57   \n",
      "3                   Harper Lee            4.25   \n",
      "4          F. Scott Fitzgerald            3.89   \n",
      "\n",
      "                                            all_tags  \n",
      "0  favorites, currently-reading, young-adult, fic...  \n",
      "1  to-read, favorites, fantasy, currently-reading...  \n",
      "2  young-adult, fantasy, favorites, vampires, ya,...  \n",
      "3  classics, favorites, to-read, classic, histori...  \n",
      "4  classics, favorites, fiction, classic, books-i...  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Merge with books metadata\n",
    "books_enriched = books.merge(\n",
    "    books_with_tags,\n",
    "    left_on='book_id',  # Check column name - might be 'id' or 'book_id'\n",
    "    right_on='goodreads_book_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Enriched books dataset: {books_enriched.shape}\")\n",
    "print(f\"Books with tags: {books_enriched['all_tags'].notna().sum()}\")\n",
    "print(f\"Books without tags: {books_enriched['all_tags'].isna().sum()}\")\n",
    "print(\"\\nSample:\")\n",
    "print(books_enriched[['title', 'authors', 'average_rating', 'all_tags']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116bdd8b",
   "metadata": {},
   "source": [
    "#### Step 4: Filter for Emotion-Tagged Books\n",
    "\n",
    "**What's happening:** Identify which books have tags related to emotions using pattern matching.\n",
    "\n",
    "**Method:**\n",
    "1. Search the `all_tags` column for any of our emotion keywords (e.g., \"sad\", \"uplifting\", \"comfort\")\n",
    "2. Create a boolean flag: `has_emotion_tags`\n",
    "3. Filter to get subset of emotion-relevant books\n",
    "\n",
    "**Why this matters:**\n",
    "- Tells us data coverage: Can we build an emotion recommender with existing tags alone?\n",
    "- If coverage is low (<20%), we need external resources (NRC Emotion Lexicon, sentiment analysis on descriptions)\n",
    "- If coverage is high (>50%), tags are a strong signal for training\n",
    "\n",
    "**Next decision:** Based on % of emotion-tagged books, choose modeling approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b8359",
   "metadata": {},
   "source": [
    "### 11.2 Filter for Books with Emotion-Related Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57ce2230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Books with emotion-related tags: 3630 / 10000\n",
      "Percentage: 36.3%\n",
      "\n",
      "Sample emotion-tagged books:\n",
      "                                               title  \\\n",
      "0            The Hunger Games (The Hunger Games, #1)   \n",
      "2                            Twilight (Twilight, #1)   \n",
      "4                                   The Great Gatsby   \n",
      "5                             The Fault in Our Stars   \n",
      "9                                Pride and Prejudice   \n",
      "11                         Divergent (Divergent, #1)   \n",
      "15  The Girl with the Dragon Tattoo (Millennium, #1)   \n",
      "16              Catching Fire (The Hunger Games, #2)   \n",
      "19                 Mockingjay (The Hunger Games, #3)   \n",
      "21                                  The Lovely Bones   \n",
      "\n",
      "                       authors  average_rating  \\\n",
      "0              Suzanne Collins            4.34   \n",
      "2              Stephenie Meyer            3.57   \n",
      "4          F. Scott Fitzgerald            3.89   \n",
      "5                   John Green            4.26   \n",
      "9                  Jane Austen            4.24   \n",
      "11               Veronica Roth            4.24   \n",
      "15  Stieg Larsson, Reg Keeland            4.11   \n",
      "16             Suzanne Collins            4.30   \n",
      "19             Suzanne Collins            4.03   \n",
      "21                Alice Sebold            3.77   \n",
      "\n",
      "                                             all_tags  \n",
      "0   favorites, currently-reading, young-adult, fic...  \n",
      "2   young-adult, fantasy, favorites, vampires, ya,...  \n",
      "4   classics, favorites, fiction, classic, books-i...  \n",
      "5   favorites, to-read, young-adult, fiction, ya, ...  \n",
      "9   classics, favorites, fiction, romance, classic...  \n",
      "11  favorites, currently-reading, to-read, young-a...  \n",
      "15  to-read, currently-reading, fiction, mystery, ...  \n",
      "16  young-adult, dystopia, fantasy, sci-fi, to-rea...  \n",
      "19  currently-reading, favorites, young-adult, dys...  \n",
      "21  to-read, fiction, favorites, mystery, books-i-...  \n"
     ]
    }
   ],
   "source": [
    "# Find books with emotion-related tags\n",
    "emotion_pattern = '|'.join(emotion_keywords)\n",
    "books_enriched['has_emotion_tags'] = books_enriched['all_tags'].str.contains(\n",
    "    emotion_pattern, \n",
    "    case=False, \n",
    "    na=False\n",
    ")\n",
    "\n",
    "emotion_books = books_enriched[books_enriched['has_emotion_tags']]\n",
    "\n",
    "print(f\"üìö Books with emotion-related tags: {len(emotion_books)} / {len(books_enriched)}\")\n",
    "print(f\"Percentage: {len(emotion_books)/len(books_enriched)*100:.1f}%\")\n",
    "print(\"\\nSample emotion-tagged books:\")\n",
    "print(emotion_books[['title', 'authors', 'average_rating', 'all_tags']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3ace5c",
   "metadata": {},
   "source": [
    "### 11.3 Key Insights from Merging\n",
    "\n",
    "**What we learned:**\n",
    "- How many books have ANY tags\n",
    "- How many have emotion-specific tags\n",
    "- Which books are good candidates for emotion-based recommendations\n",
    "- Data quality: missing tags = problem for content-based approaches\n",
    "\n",
    "**Next steps:**\n",
    "- If few emotion tags ‚Üí need external emotion lexicons or NLP\n",
    "- If many ‚Üí can use tags as training signal\n",
    "- Consider hybrid: tags + book descriptions + external knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e659f7",
   "metadata": {},
   "source": [
    "## 12. Check for Book Descriptions\n",
    "\n",
    "**Critical decision:** Do we have rich text (descriptions/summaries) to use for semantic matching?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "769775e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available book columns:\n",
      "['id', 'book_id', 'best_book_id', 'work_id', 'books_count', 'isbn', 'isbn13', 'authors', 'original_publication_year', 'original_title', 'title', 'language_code', 'average_rating', 'ratings_count', 'work_ratings_count', 'work_text_reviews_count', 'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5', 'image_url', 'small_image_url']\n",
      "\n",
      "Potential description columns: ['work_text_reviews_count']\n",
      "\n",
      "Sample book data:\n",
      "                                               title  \\\n",
      "0            The Hunger Games (The Hunger Games, #1)   \n",
      "1  Harry Potter and the Sorcerer's Stone (Harry P...   \n",
      "2                            Twilight (Twilight, #1)   \n",
      "3                              To Kill a Mockingbird   \n",
      "4                                   The Great Gatsby   \n",
      "\n",
      "                       authors  work_text_reviews_count  \n",
      "0              Suzanne Collins                   155254  \n",
      "1  J.K. Rowling, Mary GrandPr√©                    75867  \n",
      "2              Stephenie Meyer                    95009  \n",
      "3                   Harper Lee                    72586  \n",
      "4          F. Scott Fitzgerald                    51992  \n"
     ]
    }
   ],
   "source": [
    "# Check available columns\n",
    "print(\"Available book columns:\")\n",
    "print(books.columns.tolist())\n",
    "\n",
    "# Check for description-like columns\n",
    "description_cols = [col for col in books.columns if 'desc' in col.lower() or 'summary' in col.lower() or 'text' in col.lower()]\n",
    "print(f\"\\nPotential description columns: {description_cols}\")\n",
    "\n",
    "# Sample a few rows to see what we have\n",
    "print(\"\\nSample book data:\")\n",
    "print(books[['title', 'authors'] + description_cols].head() if description_cols else books[['title', 'authors']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dab8d3",
   "metadata": {},
   "source": [
    "## 13. Save Processed Data\n",
    "\n",
    "Save the enriched dataset so we don't have to re-run merges every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd369381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved books_enriched.csv: (10000, 27)\n",
      "‚úÖ Saved emotion_books.csv: (3630, 27)\n",
      "\n",
      "üìÇ Processed data saved to /data/processed/\n"
     ]
    }
   ],
   "source": [
    "# Save the enriched books dataset\n",
    "books_enriched.to_csv(\"../data/processed/books_enriched.csv\", index=False)\n",
    "print(f\"‚úÖ Saved books_enriched.csv: {books_enriched.shape}\")\n",
    "\n",
    "# Also save the emotion-filtered subset for quick access\n",
    "emotion_books.to_csv(\"../data/processed/emotion_books.csv\", index=False)\n",
    "print(f\"‚úÖ Saved emotion_books.csv: {emotion_books.shape}\")\n",
    "\n",
    "print(\"\\nüìÇ Processed data saved to /data/processed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054da472",
   "metadata": {},
   "source": [
    "## 14. Next Steps Summary\n",
    "\n",
    "### ‚úÖ Completed:\n",
    "- Loaded and explored GoodReads datasets\n",
    "- Merged books with tags\n",
    "- Identified emotion-tagged books\n",
    "- Saved processed data\n",
    "\n",
    "### üéØ Next Actions:\n",
    "\n",
    "**Phase 1: Data Preprocessing** (`src/data/make_dataset.py`)\n",
    "- Handle missing tags\n",
    "- Text cleaning and normalization\n",
    "- Train/test split\n",
    "\n",
    "**Phase 2: Feature Engineering** (`src/features/build_features.py`)\n",
    "- TF-IDF vectorization on tags/titles\n",
    "- (Optional) Sentence embeddings if descriptions available\n",
    "- Create emotion-to-feature mappings\n",
    "\n",
    "**Phase 3: Modeling**\n",
    "- **Baseline:** TF-IDF + KNN (`train_tfidf_knn.py`)\n",
    "- **Advanced:** Sentence-BERT embeddings (`train_embedding_model.py`)\n",
    "\n",
    "**Phase 4: Evaluation** (`evaluate_models.py`)\n",
    "- Precision@K, Recall@K, NDCG\n",
    "- Compare baseline vs advanced\n",
    "\n",
    "**Phase 5: Deployment** (`app_streamlit.py`)\n",
    "- Interactive emotion-to-book recommender UI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
